# Ollama Container Inference and Sensitive Data Masking using cURL in C

This project demonstrates how to:  
‚úÖ **Send an inference request** to the **Ollama** container using a C program that executes a `curl` command.  
‚úÖ **Mask sensitive data** (e.g., emails, names, URLs) using **Presidio** and handle potential errors.  

---

## **üõ† Prerequisites**  

Ensure you have the following installed on your system:  

### **1Ô∏è‚É£ Ollama Container**  
Ollama should be running on your system. If not installed, follow the official guide:  
[Ollama Installation](https://ollama.com)  

### **2Ô∏è‚É£ Presidio for Sensitive Data Masking**  
We use **Presidio Analyzer and Anonymizer** to detect and mask sensitive data (e.g., emails, phone numbers, names).  

#### **Install and Run Presidio using Docker**  
```sh
# Pull Presidio Docker images
docker pull mcr.microsoft.com/presidio-analyzer
docker pull mcr.microsoft.com/presidio-anonymizer

# Start Presidio containers
docker compose up -d
```

#### **Verify that Presidio is running**  
```sh
docker ps
```
You should see `presidio-analyzer` and `presidio-anonymizer` running.  

### **3Ô∏è‚É£ GCC Compiler**  
Install GCC if not already installed:  
```sh
# Ubuntu/Debian
sudo apt update && sudo apt install gcc -y  

# macOS (Homebrew)
brew install gcc  
```

### **4Ô∏è‚É£ cURL**  
Ensure `curl` is installed:  
```sh
# Ubuntu/Debian
sudo apt install curl -y  

# macOS
brew install curl  
```

---

## **üöÄ Running the C Program**  

This C program:  
‚úÖ Sends an inference request to the Ollama API.  
‚úÖ Processes the response and saves it to a text file.  
‚úÖ Uses Presidio to mask sensitive information before processing.  

### **üîπ Compile the Program**  
```sh
gcc -o mask_sensitive_info mask_sensitive_info.c
```

### **üîπ Run the Program**  
```sh
./mask_sensitive_info
```

---

## **üîç Troubleshooting**  

### **1Ô∏è‚É£ Presidio Not Detecting Sensitive Data**  
Run a test request manually to verify if Presidio is working:  
```sh
curl -X POST "http://127.0.0.1:5002/analyze" \
-H "Content-Type: application/json" \
-d '{"text": "My name is John Doe and my email is johndoe@example.com.", "language": "en"}'
```

If you see an error, check Presidio logs:  
```sh
docker logs presidio-presidio-analyzer-1
```

If the error mentions missing Spacy models, install them:  
```sh
docker exec -it presidio-presidio-analyzer-1 bash
python -m spacy download en_core_web_lg
exit
docker restart presidio-presidio-analyzer-1
```

### **2Ô∏è‚É£ Ollama API Not Responding**  
Ensure the Ollama container is running:  
```sh
docker ps | grep ollama
```

If it's not running, restart it:  
```sh
docker restart ollama-container-name
```

Then test with:  
```sh
curl http://127.0.0.1:5001/generate
```

